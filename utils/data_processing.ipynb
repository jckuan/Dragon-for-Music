{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect `data/sports`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#users: 35598\n",
      "#items: 18357\n",
      "#filtered interactions: 296337\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "inter_file_path = '/nas/MusicRecommendation/data'\n",
    "dataset_name = 'sports'\n",
    "\n",
    "# Load inter_file\n",
    "inter_df = pd.read_csv(f'{inter_file_path}/{dataset_name}/sports14-indexed-v4.inter', sep='\\t')\n",
    "\n",
    "# Inspect the dataframe\n",
    "inter_df[['userID', 'itemID', 'x_label']].head()\n",
    "print(f'#users: {len(inter_df[\"userID\"].unique())}')\n",
    "print(f'#items: {len(inter_df[\"itemID\"].unique())}')\n",
    "print(f'#filtered interactions: {len(inter_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of image_feat: (18357, 4096)\n",
      "Shape of text_feat: (18357, 384)\n"
     ]
    }
   ],
   "source": [
    "image_feat = np.load(f'{inter_file_path}/{dataset_name}/image_feat.npy', allow_pickle=True)\n",
    "text_feat = np.load(f'{inter_file_path}/{dataset_name}/text_feat-v1.npy', allow_pickle=True)\n",
    "print(f'Shape of image_feat: {image_feat.shape}')\n",
    "print(f'Shape of text_feat: {text_feat.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music4All: Interaction data\n",
    "\n",
    "**`interaction.json`**\n",
    "```\n",
    "{\n",
    "  0: [12233, 23344, ...],\n",
    "  1: [],\n",
    "  ...\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "\n",
    "music4all_dir = '/nas/MusicRecommendation/Music4All/processed'\n",
    "inter_path = f'{music4all_dir}/interactions.json'\n",
    "attr_path = f'{music4all_dir}/attributes.json'\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open(inter_path, 'r') as file:\n",
    "    interactions = json.load(file)\n",
    "with open(attr_path, 'r') as file:\n",
    "    attributes = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#filtered interactions: 5058234\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Count item occurrences to filter 5-core items\n",
    "item_counts = {}\n",
    "for items in interactions.values():\n",
    "    for item in items:\n",
    "        item_counts[item] = item_counts.get(item, 0) + 1\n",
    "\n",
    "# Step 2: Filter users and items to retain only those with at least 5 interactions\n",
    "filtered_interactions = {}\n",
    "valid_users = []  # Keep track of valid users\n",
    "for user, items in interactions.items():\n",
    "    filtered_items = [item for item in items if item_counts.get(item, 0) >= 5]\n",
    "    if len(filtered_items) >= 5:\n",
    "        valid_users.append(int(user))  # Store valid user IDs\n",
    "        filtered_interactions[user] = filtered_items\n",
    "\n",
    "# Create user ID mapping\n",
    "user_id_map = {old_id: new_id for new_id, old_id in enumerate(sorted(valid_users))}\n",
    "\n",
    "# Step 3: Split interactions into train, validation, and test sets (8:1:1)\n",
    "train_data, valid_data, test_data = [], [], []\n",
    "for old_user, items in filtered_interactions.items():\n",
    "    new_user = user_id_map[int(old_user)]  # Map to new sequential ID\n",
    "    random.shuffle(items)\n",
    "    train_size = int(0.8 * len(items))\n",
    "    valid_size = int(0.1 * len(items))\n",
    "    \n",
    "    # Assign labels: 0 for train, 1 for valid, 2 for test\n",
    "    train_data.extend([(new_user, item, 0) for item in items[:train_size]])\n",
    "    valid_data.extend([(new_user, item, 1) for item in items[train_size:train_size + valid_size]])\n",
    "    test_data.extend([(new_user, item, 2) for item in items[train_size + valid_size:]])\n",
    "\n",
    "# Step 4: Combine all data into a single dataframe\n",
    "all_data = train_data + valid_data + test_data\n",
    "df = pd.DataFrame(all_data, columns=['userID', 'itemID', 'x_label'])\n",
    "\n",
    "# Save the dataframe to CSV\n",
    "df.to_csv(f'{inter_file_path}/Music4All/filtered_interactions.csv', index=False, sep='\\t')\n",
    "\n",
    "df.head()\n",
    "print(f'#filtered interactions: {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ztorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
